import streamlit as st
import yfinance as yf
import pandas as pd
import plotly.graph_objects as go
import numpy as np
import cvxpy as cp
import matplotlib.pyplot as plt
from sklearn.utils import resample
import plotly.graph_objects as go
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
import plotly.express as px
import plotly.figure_factory as ff

# ================================,
# Configuraci√≥n inicial de la App
# ================================
st.set_page_config(
    page_title="üî• Dashboard Acero-Aranceles 2025 üëΩ",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="üìà"
)

# ================================
# Barra lateral - Configuraci√≥n
# ================================
st.sidebar.header("‚öôÔ∏è Configuraci√≥n del Espacio")
with st.sidebar:
    start_date = st.date_input("üìÖ Fecha de inicio", value=pd.to_datetime("2010-01-01"))
    end_date = st.date_input("üìÖ Fecha final", value=pd.to_datetime("today"))

    # Definir tickers
    tickers = {
        "Ternium M√©xico": "TX.MX",
        "Grupo Simec": "SIMECB.MX",
        "Industrias CH": "ICHB.MX",
        "Orbia Advance Corporation": "ORBIA.MX",
        "Grupo Industrial Saltillo": "GISSAA.MX"

    }

    # Selecci√≥n de empresas
    selected_companies = st.multiselect(
        "üè≠ Selecciona empresas",
        options=list(tickers.keys()),
        default=list(tickers.keys())
    )

    if len(selected_companies) == 0:
        st.error("‚ö†Ô∏è Por favor, selecciona al menos una acci√≥n para continuar ‚ö†Ô∏è")
        st.stop()




# Descargar datos hist√≥ricos
@st.cache_data
def load_data(tickers, start_date, end_date):
    data_dict = {}
    for empresa, ticker in tickers.items():
        data = yf.download(ticker, start=start_date, end=end_date)
        data_dict[empresa] = data
    return data_dict

data_dict = load_data(tickers, start_date, end_date)

# Fechas importantes para l√≠neas de eventos
event_dates = {
    "Anuncio de aranceles (Trump)": "2025-02-09",
    "Aranceles impuestos (USA)": "2025-03-12",
    "Decisi√≥n pendiente (Sheinbaum)": "2025-04-02"
}

# ================================
# Funci√≥n para l√≠neas de eventos
# ================================
def add_event_lines(fig):
    offset = 0.0
    for label, date_str in event_dates.items():
        x_val = pd.to_datetime(date_str).to_pydatetime()
        fig.add_vline(x=x_val, line_dash="dash", line_color="red")
        fig.add_annotation(
            x=x_val,
            y=1.05 + offset,
            yref="paper",
            text=label,
            showarrow=False,
            xanchor="center",
            font=dict(color="red", size=10)
        )
        offset += 0.05

# ================================
# Contenido principal con pesta√±as
# ================================
tab0, tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs([
    "üè† Contexto",
    "üìâ Retornos Diarios",
    "üöÄ Retornos Acumulados",
    "üíµ Cambio Absoluto",
    "üìä Distribuci√≥n Retornos",
    "üßÆ Estad√≠sticas",
    "üíº Carteras 2025",
    "üí∞ Cartera Extra",
    "üß† Pron√≥stico",
    "üìÖ Notas"

])

# ================================
# Pesta√±a 0: Contexto y Precios
# ================================
with tab0:
    st.markdown("""
    ## üìà Bienvenido al Campo de Batalla Financiero ‚öîÔ∏è
    **Contexto clave de 2025:**
    üìÖ **9/feb**: Trump inicia guerra comercial üí£ ‚Üí üìÖ **12/mar**: EE.UU. impone 25% arancel ‚ö†Ô∏è
    üìÖ **2/abr**: Sheinbaum contraataca üá≤üáΩ ‚Üí üìâüìà Acciones en modo monta√±a rusa üé¢
    """)

    # Gr√°fico de precios de cierre
    close_prices = pd.concat([data_dict[empresa]["Close"] for empresa in selected_companies], axis=1)
    close_prices.columns = selected_companies

    fig_price = go.Figure()
    for empresa in close_prices.columns:
        fig_price.add_trace(go.Scatter(x=close_prices.index, y=close_prices[empresa], mode='lines', name=empresa))
    add_event_lines(fig_price)
    fig_price.update_layout(title="üî• Evoluci√≥n del Precio de Cierre (MXN)", height=600)
    st.plotly_chart(fig_price, use_container_width=True)

    # Indicadores de √∫ltimos precios
    st.subheader("üí∞ √öltimos Precios de Cierre (MXN)")
    cols = st.columns(len(selected_companies))
    for idx, empresa in enumerate(selected_companies):
        last_price = close_prices[empresa].iloc[-1]       #DADO QUE EL ACTIVO TARDA EN CAMBIAR DE PRECIO, NOS VAMOS A ILOC 1 PARA QUE NO MUESTRE VALORES NaN
        cols[idx].metric(
            label=f"{empresa} {'üìà' if last_price > close_prices[empresa].iloc[-3] else 'üìâ'}",
            value=f"${last_price:,.2f} MXN"
        )

    # Tabla de precios
    st.subheader("üìã Tabla Hist√≥rica de Precios")
    st.dataframe(close_prices.tail().style.format("${:,.2f}"), height=200)

# ================================
# Pesta√±a 1: Retornos Diarios
# ================================
with tab1:
    st.markdown("## üìâüìà Retornos Diarios: ¬øD√≥nde lati√≥ fuerte el coraz√≥n burs√°til? üíì")

    returns = close_prices.pct_change().dropna()

    # Gr√°fico de retornos
    fig_returns = go.Figure()
    for empresa in returns.columns:
        fig_returns.add_trace(go.Scatter(x=returns.index, y=returns[empresa], mode='lines', name=empresa))
    add_event_lines(fig_returns)
    fig_returns.update_layout(title="üé¢ Evoluci√≥n de Retornos Diarios (%)", height=600)
    st.plotly_chart(fig_returns, use_container_width=True)

    # Indicadores de √∫ltimos retornos
    st.subheader("üîÑ √öltimos Retornos Diarios")
    cols = st.columns(len(selected_companies))
    for idx, empresa in enumerate(selected_companies):
        last_return = returns[empresa].iloc[-1] * 100   #DADO QUE EL ACTIVO TARDA EN CAMBIAR DE PRECIO, NOS VAMOS A ILOC 2 PARA QUE NO MUESTRE VALORES NaN
        cols[idx].metric(
            label=f"{empresa} {'üü¢' if last_return > 0 else 'üî¥'}",
            value=f"{last_return:.2f}%"
        )

    # Tabla de retornos
    st.subheader("üìã Tabla de Retornos Diarios")
    st.dataframe(returns.tail().style.format("{:.2%}"), height=200)

# ================================
# Pesta√±a 2: Retornos Acumulados
# ================================
with tab2:
    st.markdown("## üöÄ Retornos Acumulados: El viaje completo del capital üß≥")

    cumulative_returns = (1 + returns).cumprod() - 1

    # Gr√°fico acumulado
    fig_cum = go.Figure()
    for empresa in cumulative_returns.columns:
        fig_cum.add_trace(go.Scatter(x=cumulative_returns.index, y=cumulative_returns[empresa], mode='lines', name=empresa))
    add_event_lines(fig_cum)
    fig_cum.update_layout(title="üì¶ Retornos Acumulados desde Inicio (%)", height=600)
    st.plotly_chart(fig_cum, use_container_width=True)

    # Indicadores acumulados
    st.subheader("üßÆ Retorno Total Acumulado")
    cols = st.columns(len(selected_companies))
    for idx, empresa in enumerate(selected_companies):
        total_return = cumulative_returns[empresa].iloc[-1] * 100  #DADO QUE EL ACTIVO TARDA EN CAMBIAR DE PRECIO, NOS VAMOS A ILOC 1 PARA QUE NO MUESTRE VALORES NaN
        cols[idx].metric(
            label=f"{empresa} {'üöÄ' if total_return > 0 else 'üí£'}",
            value=f"{total_return:.2f}%"
        )

    # Tabla acumulada
    st.subheader("üìã Tabla de Retornos Acumulados")
    st.dataframe(cumulative_returns.tail().style.format("{:.2%}"), height=200)

# ================================
# Pesta√±a 3: Cambio Absoluto
# ================================
with tab3:
    st.markdown("## üíµ Cambio Absoluto: ¬øCu√°nto lati√≥ el precio cada d√≠a? üíì")

    price_change = close_prices.diff().dropna()

    # Gr√°fico de barras
    fig_price_change = go.Figure()
    for empresa in price_change.columns:
        fig_price_change.add_trace(go.Bar(
            x=price_change.index,
            y=price_change[empresa],
            name=empresa
        ))
    add_event_lines(fig_price_change)
    fig_price_change.update_layout(
        title="üîÑ Cambio Diario Absoluto en Pesos",
        height=600,
        barmode='group'
    )
    st.plotly_chart(fig_price_change, use_container_width=True)

    # Indicadores de √∫ltimo cambio
    st.subheader("üí∏ √öltimo Cambio Diario (MXN)")
    cols = st.columns(len(selected_companies))
    for idx, empresa in enumerate(selected_companies):
        last_change = price_change[empresa].iloc[-1]
        cols[idx].metric(
            label=f"{empresa} {'üíπ' if last_change > 0 else 'üîª'}",
            value=f"${last_change:,.2f}"
        )

    # Tabla de cambios
    st.subheader("üìã Tabla de Cambios Absolutos")
    st.dataframe(price_change.tail().style.format("${:,.2f}"), height=200)

# ================================
# Pesta√±a 4: Distribuci√≥n Retornos
# ================================
with tab4:
    st.markdown("## üìä Distribuci√≥n de Retornos: ¬øD√≥nde se esconden las sorpresas? üé≠")

    # Histograma
    fig_hist = go.Figure()
    for empresa in returns.columns:
        fig_hist.add_trace(go.Histogram(
            x=returns[empresa],
            name=empresa,
            opacity=0.5,
            histnorm='percent'
        ))
    fig_hist.update_layout(
        title="üì¶ Distribuci√≥n de Retornos Diarios (%)",
        height=600,
        barmode='overlay'
    )
    st.plotly_chart(fig_hist, use_container_width=True)

    # Indicadores de volatilidad
    st.subheader("üå™Ô∏è Volatilidad Reciente (√öltimos 30 d√≠as)")
    cols = st.columns(len(selected_companies))
    for idx, empresa in enumerate(selected_companies):
        vol = returns[empresa].tail(30).std() * 100
        cols[idx].metric(
            label=f"{empresa}",
            value=f"{vol:.2f}%",
            delta="Alta volatilidad" if vol > 5 else "Estable"
        )

    # Tabla de retornos
    st.subheader("üìã Datos Crudos de Retornos")
    st.dataframe(returns.tail().style.format("{:.2%}"), height=200)

# ================================
# Pesta√±a 5: Estad√≠sticas Rendimiento
# ================================
with tab5:
    st.markdown("## üßÆ Estad√≠sticas Clave: El term√≥metro del rendimiento üå°Ô∏è")

    # Calcular estad√≠sticas
    stats = pd.DataFrame(columns=[
        "Return Promedio Diario",
        "Volatilidad Diaria",
        "Sharpe Ratio",
        "M√°xima Ca√≠da"
    ])

    for empresa in selected_companies:
        daily_returns = returns[empresa]
        stats.loc[empresa] = [
            daily_returns.mean() * 100,          # Return promedio
            daily_returns.std() * 100,           # Volatilidad
            daily_returns.mean() / daily_returns.std(),  # Sharpe
            (daily_returns.cummin()).min() * 100 # M√°xima ca√≠da
        ]

    # Mostrar m√©tricas en cards
    st.subheader("üìå Resumen Ejecutivo")
    cols = st.columns(len(selected_companies))
    for idx, empresa in enumerate(selected_companies):
        with cols[idx]:
            st.metric(label=f"üèÜ Mejor d√≠a {empresa}",
                     value=f"{returns[empresa].max()*100:.2f}%")
            st.metric(label=f"üí• Peor d√≠a {empresa}",
                     value=f"{returns[empresa].min()*100:.2f}%")

    # Tabla de estad√≠sticas
    st.subheader("üìã Tabla Completa de M√©tricas")
    st.dataframe(stats.style.format({
        "Return Promedio Diario": "{:.2f}%",
        "Volatilidad Diaria": "{:.2f}%",
        "Sharpe Ratio": "{:.2f}",
        "M√°xima Ca√≠da": "{:.2f}%"
    }), height=400)





# ================================
# Pesta√±a 7: Optimizaci√≥n  NPEB de Portafolio
# ================================
with tab7:
    st.markdown("## üß† Portafolio √ìptimo Bayesiano (NPEB)")
    st.markdown(r"""
    ### üìö Modelo de Optimizaci√≥n Bayesiana
    Se estima el portafolio √≥ptimo utilizando el m√©todo **No Parametric Empirical Bayes (NPEB)**, que incorpora la incertidumbre en los par√°metros a trav√©s de bootstrap.

    **Estimaci√≥n de par√°metros:**

    Se generan $B$ muestras bootstrap de los retornos para calcular:

    - La media:
      $$\mu_n = \frac{1}{B}\sum_{b=1}^{B} \mu_b$$

    - La matriz de segundo momento:
      $$V_n = \frac{1}{B}\sum_{b=1}^{B} \Big(\Sigma_b + \mu_b \mu_b^T\Big)$$

    donde $\mu_b$ y $\Sigma_b$ son la media y covarianza obtenidas de cada muestra.

    **Problema de optimizaci√≥n:**

    $$\min_{w}\; \lambda\, w^T V_n w \;-\; \eta\, w^T \mu_n$$

    sujeto a:
    $$\sum_{i} w_i = 1,\quad w_i \geq 0.$$

    **Referencia:**
    Efron, B. (2013). *Bayesian inference and the parametric bootstrap*. arXiv preprint arXiv:1301.2936. [Disponible en](https://arxiv.org/abs/1301.2936)
    """)


    # Par√°metros para el modelo (Œª, B, etc.)
    st.markdown("### ‚öôÔ∏è Selecci√≥n de Par√°metros del Modelo Bayesiano")
    col_par, col_boot = st.columns(2)
    with col_par:
        lam = st.slider("Aversi√≥n al riesgo (Œª)", 0.1, 20.0, 10.0, 0.1,
                        help="Valores m√°s altos = Mayor penalizaci√≥n a la volatilidad [Recomendado: 5-15]")
    with col_boot:
        B = st.slider("Muestras bootstrap (B)", 100, 2000, 500, 100,
                      help="N√∫mero de simulaciones para estimaci√≥n [Recomendado: 500-1000]")

    # En el c√≥digo de referencia, NO se permite venta en corto (w >= 0).
    allow_short = False

    # 1) Verificar datos hist√≥ricos disponibles
    min_date = min([data.index[0] for data in data_dict.values()]).date()
    max_date = max([data.index[-1] for data in data_dict.values()]).date()

    # 2) Ajustar la fecha por defecto al rango [min_date, max_date]
    default_start = pd.to_datetime("2020-01-04").date()
    if default_start < min_date:
        default_start = min_date
    default_end = pd.to_datetime("today").date()
    if default_end > max_date:
        default_end = max_date

    st.warning(f"""
    üìÖ **Rango de datos disponible:**
    {min_date.strftime('%d/%m/%Y')} - {max_date.strftime('%d/%m/%Y')}
    """)

    # 3) Selecci√≥n de fechas para entrenamiento del portafolio
    col1, col2 = st.columns(2)
    with col1:
        port_start = st.date_input(
            "Fecha inicial entrenamiento",
            value=default_start,
            min_value=min_date,
            max_value=max_date
        )
    with col2:
        port_end = st.date_input(
            "Fecha final entrenamiento",
            value=default_end,
            min_value=min_date,
            max_value=max_date
        )

    # 4) Cargar y preparar datos

    # Quita o comenta el decorador para evitar datos cacheados
    # @st.cache_data(hash_funcs={list: lambda l: tuple(l)})
    def prepare_portfolio_data(tickers, selected_companies, start_date, end_date):
        data_prices = yf.download([tickers[e] for e in selected_companies],
                                  start=start_date, end=end_date)["Close"]
        data_prices = data_prices.dropna(axis=0, how="any")
        returns = data_prices.pct_change().dropna()
        return returns




    try:
        #returns = prepare_portfolio_data(tickers, port_start, port_end)

        returns = prepare_portfolio_data(tickers, selected_companies, port_start, port_end)
       # returns = prepare_portfolio_data(tickers, tuple(selected_companies), port_start, port_end)

        if returns.empty:
            st.error("‚ùå No hay suficientes datos para el periodo seleccionado")
            st.stop()

        # === 5) Estimaci√≥n de par√°metros (NPEB) ===

        # @st.cache_data
        def estimate_parameters(_returns, B_samples):
            n, m = _returns.shape
            mu_boot = []
            Sigma_boot = []
            returns_np = _returns.values

            for _ in range(B_samples):
                sample = resample(returns_np, n_samples=n, replace=True)
                mu_b = np.mean(sample, axis=0)
                Sigma_b = np.cov(sample, rowvar=False)
                mu_boot.append(mu_b)
                Sigma_boot.append(Sigma_b)

            mu_n = np.mean(mu_boot, axis=0)
            V_n = np.mean([
                Sigma_boot[b] + np.outer(mu_boot[b], mu_boot[b])
                for b in range(B_samples)
            ], axis=0)
            return mu_n, V_n








        mu_n, V_n = estimate_parameters(returns, B)
        m = len(mu_n)

        # === 6) Funci√≥n de optimizaci√≥n bayesiana (con w >= 0) ===
        def solve_bayesian_portfolio(mu, V, lam, eta):
            w = cp.Variable(m)
            objective = cp.Minimize(lam * cp.quad_form(w, V) - eta * (mu @ w))
            constraints = [cp.sum(w) == 1, w >= 0]
            prob = cp.Problem(objective, constraints)
            prob.solve(solver=cp.OSQP)
            if prob.status == "optimal":
                return w.value
            else:
                return None

        # === 7) Escaneo de Œ∑ para replicar EXACTO el c√≥digo de referencia ===
        eta_values = np.linspace(0.1, 5, 50)
        best_eta = None
        best_w = None
        best_utility = -np.inf

        for e in eta_values:
            w_try = solve_bayesian_portfolio(mu_n, V_n, lam, e)
            if w_try is not None:
                port_ret = returns.values @ w_try
                util = np.mean(port_ret) - lam * np.var(port_ret)
                if util > best_utility:
                    best_utility = util
                    best_eta = e
                    best_w = w_try

        if best_w is None:
            st.error("‚ö†Ô∏è No se pudo encontrar soluci√≥n √≥ptima. Ajusta los par√°metros.")
            st.stop()

        # Comentario indicando la Œ∑ √≥ptima encontrada.
        st.success("‚úÖ Cartera NPEB optimizada correctamente!")
        st.write(f"**Œ∑ √≥ptimo encontrado:** {best_eta:.2f}  *(En el paper encontraron: 1.00)*")

        # === 8) Mostrar Resultados Cartera NPEB ===
        port_ret = returns.values @ best_w
        mean_daily = np.mean(port_ret)
        std_daily = np.std(port_ret)
        mean_ann = (1 + mean_daily)**252 - 1
        std_ann = std_daily * np.sqrt(252)
        sharpe = mean_daily/std_daily if std_daily > 0 else float('nan')

        st.markdown("### Resultados Cartera NPEB")
        c1, c2, c3 = st.columns(3)
        c1.metric("Retorno anualizado", f"{mean_ann*100:.2f}%")
        c2.metric("Volatilidad anualizada", f"{std_ann*100:.2f}%")
        c3.metric("Sharpe ratio (diario)", f"{sharpe:.4f}")

        # === 9) Cartera Markowitz (Plug-in) para comparaci√≥n (w >= 0) ===
        def markowitz_portafolio(mu, Sigma):
            w = cp.Variable(m)
            objective = cp.Minimize(cp.quad_form(w, Sigma))
            constraints = [cp.sum(w) == 1, w >= 0]
            prob = cp.Problem(objective, constraints)
            prob.solve(solver=cp.OSQP)
            if prob.status == "optimal":
                return w.value
            else:
                return None

        mu_sample = returns.mean().values
        Sigma_sample = returns.cov().values
        w_markowitz = markowitz_portafolio(mu_sample, Sigma_sample)

        if w_markowitz is not None:
            port_ret_mk = returns.values @ w_markowitz
            mean_daily_mk = np.mean(port_ret_mk)
            std_daily_mk = np.std(port_ret_mk)
            mean_ann_mk = (1 + mean_daily_mk)**252 - 1
            std_ann_mk = std_daily_mk * np.sqrt(252)
            sharpe_mk = mean_daily_mk/std_daily_mk if std_daily_mk > 0 else float('nan')

            st.markdown("### Cartera Markowitz (Plug-in)")
            cA, cB, cC = st.columns(3)
            cA.metric("Retorno anualizado", f"{mean_ann_mk*100:.2f}%")
            cB.metric("Volatilidad anualizada", f"{std_ann_mk*100:.2f}%")
            cC.metric("Sharpe ratio (diario)", f"{sharpe_mk:.4f}")
        else:
            st.warning("No se pudo resolver la cartera Markowitz con los par√°metros actuales.")

        # === 10) Tabla comparativa de Pesos de ambas carteras ===
        st.markdown("### Comparaci√≥n de Pesos de las Carteras")
        df_comparacion = pd.DataFrame({
            "Activo": selected_companies,
            "Peso NPEB (%)": np.round(best_w*100, 2),
            "Peso Markowitz (%)": np.round(w_markowitz*100, 2) if w_markowitz is not None else np.nan
        })
        st.dataframe(df_comparacion.style.format({
            "Peso NPEB (%)": "{:.2f}",
            "Peso Markowitz (%)": "{:.2f}"
        }), height=300)

        # === 11) Gr√°fico comparativo de barras de los pesos ===
        fig = go.Figure(data=[
            go.Bar(name="NPEB", x=list(selected_companies), y=best_w*100, marker_color='#1f77b4'),
            go.Bar(name="Markowitz", x=list(selected_companies), y=w_markowitz*100, marker_color='#ff7f0e')
        ])
        fig.update_layout(
            title="üî¢ Comparaci√≥n de Distribuci√≥n de Pesos",
            yaxis_title="Peso (%)",
            barmode="group",
            xaxis_tickangle=-45
        )
        st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"Error en c√°lculo: {str(e)}")





# ================================
# Pesta√±a 6: Optimizaci√≥n Portafolios Extras
#   - Portafolio Bayesiano Tradicional (prior definido por el usuario)
#   - Portafolio Risk Parity
#   - Portafolio Sharpe (M√°ximo Ratio)
#   - Portafolio MinVar (M√≠nima Varianza)
# ================================
with tab6:
    st.markdown("## üßÆ Optimizaci√≥n Portafolios 2025: Modelos Interactivos üßÆ")
    st.markdown("""
    **Contexto:**
    En esta pesta√±a podr√°s explorar cuatro nuevos modelos de optimizaci√≥n de portafolios. Cada uno te permite ajustar par√°metros clave,
    incluyendo consideraciones de impacto arancelario.
    - **Bayesiano Tradicional:** Ajusta los priors para incorporar expectativas subjetivas (por ejemplo, el impacto de aranceles) y escoge la distribuci√≥n previa (Normal o T-Student).
    - **Risk Parity:** Igualar la contribuci√≥n al riesgo de cada activo; adem√°s, puedes decidir si incluir activos de cobertura como CETES u Oro.
    - **Sharpe (M√°ximo Ratio):** Permite personalizar los retornos esperados (ajustados por aranceles) y elegir entre datos hist√≥ricos o proyecciones bayesianas.
    - **MinVar:** Optimiza para la m√≠nima varianza permitiendo restringir el peso m√°ximo asignado a cada activo y escoger el m√©todo de estimaci√≥n de la matriz de covarianza.
    """)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Par√°metros Generales para Portafolios Extras
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    with st.expander("üîß Par√°metros Generales para Portafolios Extras", expanded=True):
        # Modo arancelario global: explica c√≥mo se ajustan retornos y volatilidades.
        arancel_mode = st.checkbox("Modo Arancelario üõÉ",
                                    help="Si se activa, se reduce el retorno esperado de exportadores (por ejemplo, TX.MX en -15%) y se aumenta la volatilidad de empresas con deuda en USD (por ejemplo, ORBIA.MX +20%).")
        col_gen1, col_gen2 = st.columns(2)
        with col_gen1:
            port_start_ex = st.date_input("Fecha inicial entrenamiento",
                                          value=default_start, min_value=min_date, max_value=max_date, key="port_start_ex")
        with col_gen2:
            port_end_ex = st.date_input("Fecha final entrenamiento",
                                        value=default_end, min_value=min_date, max_value=max_date, key="port_end_ex")
        # Se cargan los datos para la optimizaci√≥n en Extras
       # returns_ex = prepare_portfolio_data(tickers, port_start_ex, port_end_ex)

        returns_ex = prepare_portfolio_data(tickers, selected_companies, port_start_ex, port_end_ex)
        if returns_ex.empty:
            st.error("‚ùå No hay suficientes datos para el periodo seleccionado en Extras")
            st.stop()

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 1. Portafolio Bayesiano Tradicional üß†
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("### üß† Portafolio Bayesiano Tradicional (Prior definido por el usuario)")
    with st.expander("Par√°metros Bayesiano Tradicional", expanded=True):
        lam_bayes = st.slider("Aversi√≥n al riesgo (Œª) [Bayesiano]", 0.1, 20.0, 10.0, step=0.1,
                              help="Valor mayor penaliza m√°s la volatilidad. Ajusta este par√°metro para controlar la aversi√≥n al riesgo.")
        st.markdown("#### üìä Ajuste de Priors (en %)")
        st.markdown("""
        Los **priors** representan tus expectativas subjetivas sobre los retornos de cada activo.
        Por ejemplo, si crees que los aranceles impactar√°n negativamente a una empresa, puedes ajustar su prior a un valor negativo.
        *Modifica estos valores seg√∫n tu an√°lisis o intuici√≥n sobre el impacto de aranceles u otros factores.*
        """)
        prior_adjustments = {}
        for empresa in selected_companies:
            # Valor de referencia: para TX.MX se sugiere -15% si Modo Arancelario est√° activo
            default_prior = -15.0 if arancel_mode and tickers[empresa] == "TX.MX" else 0.0
            prior_adjustments[empresa] = st.number_input(f"Prior para {empresa}", value=default_prior, step=0.1, format="%.2f",
                                                         help="Modifica este valor para ajustar tu expectativa sobre el retorno del activo.")
        st.markdown("#### üî¢ Probabilidad de arancel prolongado")
        prob_arancel = st.slider("Probabilidad de arancel prolongado (%)", 0, 100, 50,
                                 help="Este valor ajusta la volatilidad. Una probabilidad mayor implica un mayor incremento en la incertidumbre.")
        st.markdown("#### üìà Selecci√≥n de Distribuci√≥n Previa")
        prior_distribution = st.selectbox("Distribuci√≥n previa", options=["Normal", "T-Student"],
                                          help="""
                                          - **Normal:** Asume una distribuci√≥n sim√©trica de retornos.
                                          - **T-Student:** Permite colas m√°s pesadas, √∫til en presencia de eventos extremos o incertidumbre elevada.
                                          """)
        st.info("üí° *Consejo:* Ajusta los priors y la distribuci√≥n seg√∫n tu percepci√≥n del entorno econ√≥mico y el impacto de aranceles.")

    # C√°lculos para el portafolio Bayesiano
    mu_sample = returns_ex.mean().values            # Promedio muestral
    Sigma_sample = returns_ex.cov().values            # Matriz de covarianza muestral
    # Ajustar los retornos esperados seg√∫n los priors (convertidos de % a decimal)
    mu_adj = np.array([mu_sample[i] + (prior_adjustments[empresa] / 100.0)
                       for i, empresa in enumerate(selected_companies)])
    # Ajuste de la volatilidad: se incrementa seg√∫n el slider de probabilidad
    vol_factor = 1 + (prob_arancel / 100.0)
    Sigma_adj = Sigma_sample * vol_factor
    # Ajuste extra: en modo arancelario, para ORBIA.MX se aumenta volatilidad en 20%
    for i, empresa in enumerate(selected_companies):
        if arancel_mode and tickers[empresa] == "ORBIA.MX":
            Sigma_adj[i, :] *= 1.20
            Sigma_adj[:, i] *= 1.20

    m_assets = len(selected_companies)
    def solve_bayes_portfolio(mu, Sigma, lam, eta):
        w = cp.Variable(m_assets)
        objective = cp.Minimize(lam * cp.quad_form(w, Sigma) - eta * (mu @ w))
        constraints = [cp.sum(w) == 1, w >= 0]
        prob = cp.Problem(objective, constraints)
        prob.solve(solver=cp.OSQP)
        return w.value if prob.status == "optimal" else None

    eta_values = np.linspace(0.1, 5, 50)
    best_eta_bayes = None
    best_w_bayes = None
    best_util_bayes = -np.inf
    for eta in eta_values:
        w_try = solve_bayes_portfolio(mu_adj, Sigma_adj, lam_bayes, eta)
        if w_try is not None:
            port_ret = returns_ex.values @ w_try
            util = np.mean(port_ret) - lam_bayes * np.var(port_ret)
            if util > best_util_bayes:
                best_util_bayes = util
                best_eta_bayes = eta
                best_w_bayes = w_try

    if best_w_bayes is None:
        st.error("‚ö†Ô∏è No se pudo optimizar el Portafolio Bayesiano Tradicional. Ajusta los par√°metros.")
    else:
        st.success("‚úÖ Portafolio Bayesiano Tradicional optimizado correctamente!")
        st.write(f"**Œ∑ √≥ptimo encontrado:** {best_eta_bayes:.2f}")
        port_ret_bayes = returns_ex.values @ best_w_bayes
        mean_daily_bayes = np.mean(port_ret_bayes)
        std_daily_bayes = np.std(port_ret_bayes)
        mean_ann_bayes = (1 + mean_daily_bayes) ** 252 - 1
        std_ann_bayes = std_daily_bayes * np.sqrt(252)
        sharpe_bayes = mean_daily_bayes / std_daily_bayes if std_daily_bayes > 0 else float('nan')
        st.markdown("#### Resultados Portafolio Bayesiano Tradicional")
        col_b1, col_b2, col_b3 = st.columns(3)
        col_b1.metric("Retorno anualizado", f"{mean_ann_bayes * 100:.2f}%")
        col_b2.metric("Volatilidad anualizada", f"{std_ann_bayes * 100:.2f}%")
        col_b3.metric("Sharpe ratio", f"{sharpe_bayes:.4f}")
        st.markdown("#### Pesos del Portafolio")
        df_bayes = pd.DataFrame({
            "Activo": selected_companies,
            "Peso (%)": np.round(best_w_bayes * 100, 2)
        })
        st.dataframe(df_bayes.style.format({"Peso (%)": "{:.2f}"}))
        fig_bayes = go.Figure(data=[
            go.Bar(name="Bayesiano Tradicional", x=selected_companies, y=best_w_bayes * 100, marker_color='purple')
        ])
        fig_bayes.update_layout(title="Distribuci√≥n de Pesos - Portafolio Bayesiano",
                                yaxis_title="Peso (%)", xaxis_tickangle=-45)
        st.plotly_chart(fig_bayes, use_container_width=True)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 2. Portafolio Risk Parity ‚öñÔ∏è
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("### ‚öñÔ∏è Portafolio Risk Parity")
    with st.expander("Par√°metros Risk Parity", expanded=True):
        include_hedge = st.checkbox("Incluir activos de cobertura (CETES, Oro)", value=True,
                                    help="Al activarlo, se incluir√°n activos considerados como refugio, lo que puede disminuir la concentraci√≥n de riesgo.")
        max_vol = st.slider("Volatilidad m√°xima permitida por activo (%)", 1, 20, 10,
                            help="Limita el riesgo individual de cada activo (por ejemplo, CETES u Oro podr√≠an tener menor riesgo).")
        st.info("üí° *Consejo:* Si incluyes activos de cobertura, revisa que su baja volatilidad contribuya a una mejor diversificaci√≥n del riesgo.")
    # Para Risk Parity se busca igualar la contribuci√≥n al riesgo de cada activo.
    sigma_assets = np.sqrt(np.diag(Sigma_sample))
    sigma_assets_adj = sigma_assets.copy()
    for i, empresa in enumerate(selected_companies):
        if arancel_mode and tickers[empresa] == "ORBIA.MX":
            sigma_assets_adj[i] *= 1.20
    # Se arma la funci√≥n objetivo: minimizar la diferencia entre las contribuciones al riesgo.
    w = cp.Variable(m_assets)
    risk_parity_obj = 0
    for i in range(m_assets):
        for j in range(i + 1, m_assets):
            risk_parity_obj += cp.square(w[i] * sigma_assets_adj[i] - w[j] * sigma_assets_adj[j])
    constraints = [cp.sum(w) == 1, w >= 0]
    # Restricci√≥n para limitar la volatilidad individual (w[i]*œÉ_i <= max_vol/100)
    for i in range(m_assets):
        constraints.append(w[i] * sigma_assets_adj[i] <= max_vol / 100)
    prob_rp = cp.Problem(cp.Minimize(risk_parity_obj), constraints)
    prob_rp.solve(solver=cp.OSQP)
    if prob_rp.status != "optimal":
        st.error("‚ö†Ô∏è No se pudo optimizar el Portafolio Risk Parity. Ajusta los par√°metros.")
        risk_parity_weights = None
    else:
        risk_parity_weights = w.value
        st.success("‚úÖ Portafolio Risk Parity optimizado correctamente!")
        port_ret_rp = returns_ex.values @ risk_parity_weights
        mean_daily_rp = np.mean(port_ret_rp)
        std_daily_rp = np.std(port_ret_rp)
        mean_ann_rp = (1 + mean_daily_rp) ** 252 - 1
        std_ann_rp = std_daily_rp * np.sqrt(252)
        sharpe_rp = mean_daily_rp / std_daily_rp if std_daily_rp > 0 else float('nan')
        st.markdown("#### Resultados Portafolio Risk Parity")
        col_r1, col_r2, col_r3 = st.columns(3)
        col_r1.metric("Retorno anualizado", f"{mean_ann_rp * 100:.2f}%")
        col_r2.metric("Volatilidad anualizada", f"{std_ann_rp * 100:.2f}%")
        col_r3.metric("Sharpe ratio", f"{sharpe_rp:.4f}")
        st.markdown("#### Pesos del Portafolio")
        df_rp = pd.DataFrame({
            "Activo": selected_companies,
            "Peso (%)": np.round(risk_parity_weights * 100, 2)
        })
        st.dataframe(df_rp.style.format({"Peso (%)": "{:.2f}"}))
        fig_rp = go.Figure(data=[
            go.Bar(name="Risk Parity", x=selected_companies, y=risk_parity_weights * 100, marker_color='orange')
        ])
        fig_rp.update_layout(title="Distribuci√≥n de Pesos - Portafolio Risk Parity",
                             yaxis_title="Peso (%)", xaxis_tickangle=-45)
        st.plotly_chart(fig_rp, use_container_width=True)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 3. Portafolio Sharpe (M√°ximo Ratio) üìà
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("### üìà Portafolio Sharpe (M√°ximo Ratio)")
    with st.expander("Par√°metros Portafolio Sharpe", expanded=True):
        st.markdown("#### üìä Retornos Esperados Personalizados (en %)")
        st.markdown("""
        Ajusta los retornos esperados para cada activo.
        *Modificar estos valores afecta directamente la asignaci√≥n del portafolio; por ejemplo, si se reducen los retornos de un activo (por aranceles), este podr√≠a recibir menor peso.*
        """)
        custom_returns = {}
        for empresa in selected_companies:
            # Valor base: el retorno muestral en porcentaje
            default_ret = mu_sample[list(selected_companies).index(empresa)] * 100
            # Ajuste de arancel: para TX.MX se reduce en 15% si est√° activo el modo arancelario
            if arancel_mode and tickers[empresa] == "TX.MX":
                default_ret -= 15
            custom_returns[empresa] = st.number_input(f"Retorno esperado para {empresa}", value=default_ret, step=0.1, format="%.2f",
                                                      help="Ajusta este valor seg√∫n tus expectativas de rendimiento, considerando el posible impacto de aranceles.")
        use_historical = st.selectbox("Fuente de datos", options=["Hist√≥ricos", "Proyecciones Bayesianas"],
                                      index=0, help="Selecciona la fuente para calcular los retornos: datos hist√≥ricos o proyecciones basadas en an√°lisis bayesiano.")
        st.markdown("#### üéöÔ∏è Nivel de Aversi√≥n al Riesgo")
        risk_aversion_sharpe = st.slider("Nivel de Aversi√≥n al Riesgo", 1, 10, 5,
                                         help="Un valor mayor indica mayor aversi√≥n al riesgo, lo que influir√° en la asignaci√≥n del portafolio.")
    # C√°lculos para el portafolio Sharpe
    lam_sharpe = risk_aversion_sharpe
    mu_custom = np.array([custom_returns[empresa] / 100.0 for empresa in selected_companies])
    Sigma_custom = Sigma_sample.copy()
    for i, empresa in enumerate(selected_companies):
        if arancel_mode and tickers[empresa] == "ORBIA.MX":
            Sigma_custom[i, :] *= 1.20
            Sigma_custom[:, i] *= 1.20
    def solve_sharpe_portfolio(mu, Sigma, lam, eta):
        w = cp.Variable(m_assets)
        objective = cp.Minimize(lam * cp.quad_form(w, Sigma) - eta * (mu @ w))
        constraints = [cp.sum(w) == 1, w >= 0]
        prob = cp.Problem(objective, constraints)
        prob.solve(solver=cp.OSQP)
        return w.value if prob.status == "optimal" else None

    eta_values_sharpe = np.linspace(0.1, 5, 50)
    best_eta_sharpe = None
    best_w_sharpe = None
    best_util_sharpe = -np.inf
    for eta in eta_values_sharpe:
        w_try = solve_sharpe_portfolio(mu_custom, Sigma_custom, lam_sharpe, eta)
        if w_try is not None:
            port_ret = returns_ex.values @ w_try
            util = np.mean(port_ret) - lam_sharpe * np.var(port_ret)
            if util > best_util_sharpe:
                best_util_sharpe = util
                best_eta_sharpe = eta
                best_w_sharpe = w_try

    if best_w_sharpe is None:
        st.error("‚ö†Ô∏è No se pudo optimizar el Portafolio Sharpe. Ajusta los par√°metros.")
    else:
        st.success("‚úÖ Portafolio Sharpe optimizado correctamente!")
        st.write(f"**Œ∑ √≥ptimo encontrado:** {best_eta_sharpe:.2f}")
        port_ret_sharpe = returns_ex.values @ best_w_sharpe
        mean_daily_sharpe = np.mean(port_ret_sharpe)
        std_daily_sharpe = np.std(port_ret_sharpe)
        mean_ann_sharpe = (1 + mean_daily_sharpe) ** 252 - 1
        std_ann_sharpe = std_daily_sharpe * np.sqrt(252)
        sharpe_ratio_sharpe = mean_daily_sharpe / std_daily_sharpe if std_daily_sharpe > 0 else float('nan')
        st.markdown("#### Resultados Portafolio Sharpe")
        col_s1, col_s2, col_s3 = st.columns(3)
        col_s1.metric("Retorno anualizado", f"{mean_ann_sharpe * 100:.2f}%")
        col_s2.metric("Volatilidad anualizada", f"{std_ann_sharpe * 100:.2f}%")
        col_s3.metric("Sharpe ratio", f"{sharpe_ratio_sharpe:.4f}")
        st.markdown("#### Pesos del Portafolio")
        df_sharpe = pd.DataFrame({
            "Activo": selected_companies,
            "Peso (%)": np.round(best_w_sharpe * 100, 2)
        })
        st.dataframe(df_sharpe.style.format({"Peso (%)": "{:.2f}"}))
        fig_sharpe = go.Figure(data=[
            go.Bar(name="Portafolio Sharpe", x=selected_companies, y=best_w_sharpe * 100, marker_color='green')
        ])
        fig_sharpe.update_layout(title="Distribuci√≥n de Pesos - Portafolio Sharpe",
                                 yaxis_title="Peso (%)", xaxis_tickangle=-45)
        st.plotly_chart(fig_sharpe, use_container_width=True)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 4. Portafolio MinVar (M√≠nima Varianza) üõ°Ô∏è
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("### üõ°Ô∏è Portafolio MinVar (M√≠nima Varianza)")
    with st.expander("Par√°metros Portafolio MinVar", expanded=True):
        max_weight = st.slider("Restricci√≥n de peso m√°ximo por activo (%)", 10, 100, 30, step=5,
                               help="Limita la asignaci√≥n m√°xima a cada activo. Por ejemplo, restringir al 30% evita concentrar demasiado riesgo en un solo activo.")
        cov_method = st.selectbox("M√©todo de estimaci√≥n de matriz de covarianza", options=["Sample", "Ledoit-Wolf"],
                                  index=0, help="Elige entre la matriz de covarianza muestral o una versi√≥n robusta (Ledoit-Wolf) que puede mitigar efectos de muestras peque√±as.")
    if cov_method == "Sample":
        Sigma_minvar = Sigma_sample.copy()
    else:
        # Aqu√≠ se puede implementar Ledoit-Wolf; se usa Sample como placeholder.
        Sigma_minvar = Sigma_sample.copy()
        st.info("Uso de Sample covariance como aproximaci√≥n para Ledoit-Wolf (placeholder)")
    w_min = cp.Variable(m_assets)
    objective_min = cp.Minimize(cp.quad_form(w_min, Sigma_minvar))
    constraints_min = [cp.sum(w_min) == 1, w_min >= 0, w_min <= max_weight / 100]
    prob_minvar = cp.Problem(objective_min, constraints_min)
    prob_minvar.solve(solver=cp.OSQP)
    if prob_minvar.status != "optimal":
        st.error("‚ö†Ô∏è No se pudo optimizar el Portafolio MinVar. Ajusta los par√°metros.")
        w_minvar = None
    else:
        w_minvar = w_min.value
        st.success("‚úÖ Portafolio MinVar optimizado correctamente!")
        port_ret_minvar = returns_ex.values @ w_minvar
        mean_daily_minvar = np.mean(port_ret_minvar)
        std_daily_minvar = np.std(port_ret_minvar)
        mean_ann_minvar = (1 + mean_daily_minvar) ** 252 - 1
        std_ann_minvar = std_daily_minvar * np.sqrt(252)
        sharpe_minvar = mean_daily_minvar / std_daily_minvar if std_daily_minvar > 0 else float('nan')
        st.markdown("#### Resultados Portafolio MinVar")
        col_m1, col_m2, col_m3 = st.columns(3)
        col_m1.metric("Retorno anualizado", f"{mean_ann_minvar * 100:.2f}%")
        col_m2.metric("Volatilidad anualizada", f"{std_ann_minvar * 100:.2f}%")
        col_m3.metric("Sharpe ratio", f"{sharpe_minvar:.4f}")
        st.markdown("#### Pesos del Portafolio")
        df_minvar = pd.DataFrame({
            "Activo": selected_companies,
            "Peso (%)": np.round(w_minvar * 100, 2)
        })
        st.dataframe(df_minvar.style.format({"Peso (%)": "{:.2f}"}))
        fig_minvar = go.Figure(data=[
            go.Bar(name="MinVar", x=selected_companies, y=w_minvar * 100, marker_color='blue')
        ])
        fig_minvar.update_layout(title="Distribuci√≥n de Pesos - Portafolio MinVar",
                                 yaxis_title="Peso (%)", xaxis_tickangle=-45)
        st.plotly_chart(fig_minvar, use_container_width=True)
#----------------------------------------------------------------------------------------------------------------------------------------------------------



# ================================
# Pesta√±a 8: Pron√≥stico Avanzado
# ================================

with tab8:
    st.markdown("## üß† Pron√≥stico Avanzado - Triple M√©todo Predictivo")

    # Selector principal de m√©todo
    metodo_pronostico = st.selectbox("üîÆ Seleccione M√©todo Predictivo", options=[
        "üé≤ Simulaci√≥n Mejorada de Monte Carlo",
        "ü§ñ IA - Temporal Fusion Transformer",
        "üìâ Modelo Econom√©trico ARIMA-GARCH"
    ], help="Elija entre m√©todos cuantitativos modernos para generar pron√≥sticos")

    # =========================================================================
    # Secci√≥n 1: Simulaci√≥n Mejorada de Monte Carlo (Modelo Heston)
    # =========================================================================
    if metodo_pronostico == "üé≤ Simulaci√≥n Mejorada de Monte Carlo":
        st.markdown("### üé≤ Simulaci√≥n Mejorada de Monte Carlo (Modelo Heston)")
        with st.expander("‚öôÔ∏è Par√°metros del Modelo", expanded=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                n_sim = st.slider("N¬∫ de simulaciones", 1000, 50000, 10000, 1000,
                                  help="Mayor n√∫mero reduce varianza del pron√≥stico")
            with col2:
                dias_pronostico = st.slider("D√≠as a pronosticar", 1, 365, 30,
                                            help="Horizonte temporal del pron√≥stico")
            with col3:
                fecha_inicio = st.date_input("Fecha inicio datos",
                                             value=pd.to_datetime("2010-01-04"),
                                             min_value=pd.to_datetime("2010-01-04"))

            col4, col5 = st.columns(2)
            with col4:
                incluir_saltos = st.checkbox("Incluir saltos de volatilidad (Black Swan)",
                                             help="Modela eventos extremos con distribuci√≥n Poisson")
            with col5:
                lambda_jumps = st.slider("Intensidad saltos", 0.0, 1.0, 0.05, 0.01,
                                           disabled=not incluir_saltos,
                                           help="Frecuencia esperada de eventos extremos")

            # Control de semilla
            col6, col7 = st.columns(2)
            with col6:
                use_custom_seed = st.checkbox("üîí Usar semilla fija", help="Habilita para resultados reproducibles")
            with col7:
                if use_custom_seed:
                    seed = st.number_input("Semilla personalizada", value=42, min_value=0)
                else:
                    import time
                    seed = int(time.time() * 1000) % (2**32 - 1)

        # Selecci√≥n de acci√≥n
        accion = st.selectbox("üìà Seleccione acci√≥n para pron√≥stico", options=selected_companies)

        # Cargar datos
        data = data_dict[accion]["Close"].loc[pd.to_datetime(fecha_inicio):]
        returns = data.pct_change().dropna()

        if len(data) < 30:
            st.error("‚ùå Datos insuficientes para el per√≠odo seleccionado")
            st.stop()

        # Par√°metros del modelo Heston
        S0 = float(data.iloc[-1])
        mu = float(returns.mean() * 252)
        v0 = float(returns.var() * 252)
        kappa = 2.0    # Velocidad de reversi√≥n a la media
        theta = float(v0)
        sigma_v = 0.3  # Volatilidad de la volatilidad
        rho = -0.7     # Correlaci√≥n entre precio y volatilidad
        T = dias_pronostico / 252
        n_steps = dias_pronostico  # Se asume un paso diario

        # Simulaci√≥n Monte Carlo corregida
        @st.cache_data
        def run_heston_simulation(S0, mu, v0, kappa, theta, sigma_v, rho, T, n_steps, n_sim, lambda_jumps, incluir_saltos, seed):
            dt = T / n_steps
            prices = np.zeros((n_steps+1, n_sim))
            volatilities = np.zeros_like(prices)

            prices[0, :] = S0
            volatilities[0, :] = v0

            np.random.seed(seed)
            Z1 = np.random.normal(size=(n_steps, n_sim))
            Z2 = rho * Z1 + np.sqrt(1 - rho**2) * np.random.normal(size=(n_steps, n_sim))

            for t in range(1, n_steps+1):
                v_prev = volatilities[t-1, :]
                sqrt_v_prev = np.sqrt(np.maximum(v_prev, 0)) * np.sqrt(dt)

                # Actualizar volatilidad
                new_vol = v_prev + kappa*(theta - v_prev)*dt + sigma_v*sqrt_v_prev*Z2[t-1, :]
                volatilities[t, :] = np.maximum(new_vol, 0)

                # Manejar saltos correctamente
                if incluir_saltos:
                    jump_counts = np.random.poisson(lambda_jumps * dt, size=n_sim)
                    total_jumps = jump_counts.sum()
                    if total_jumps > 0:
                        jump_sizes = np.random.normal(-0.1, 0.2, size=total_jumps)
                        index = np.repeat(np.arange(n_sim), jump_counts)
                        jumps = np.bincount(index, weights=jump_sizes, minlength=n_sim)
                    else:
                        jumps = np.zeros(n_sim)
                else:
                    jumps = 0

                prices[t, :] = prices[t-1, :] * np.exp(
                    (mu - 0.5*v_prev)*dt +
                    sqrt_v_prev*Z1[t-1, :] +
                    jumps
                )

            return prices, volatilities

        prices_sim, vol_sim = run_heston_simulation(S0, mu, v0, kappa, theta, sigma_v, rho, T, n_steps, n_sim, lambda_jumps, incluir_saltos, seed)

        # Mostrar semilla usada
        st.info(f"üîë Semilla utilizada: `{seed}` - *Usa esta semilla para reproducir el escenario*")

        # Generar fechas para el pron√≥stico (excluyendo el √∫ltimo d√≠a hist√≥rico)
        last_date = data.index[-1]
        forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=dias_pronostico, freq='B')

        # -----------------------------------------------------------------------------
        # Gr√°fica 1: Trayectorias Simuladas con colores aleatorios
        # -----------------------------------------------------------------------------
        price_mean = prices_sim.mean(axis=1)

        # Generar fechas completas (hist√≥rico + pron√≥stico)
        full_dates = pd.date_range(start=data.index[-1], periods=len(price_mean), freq='B')

        fig_tray = go.Figure()

        # 1. Trayectorias simuladas (solo primeras 100 para claridad)
        colors = px.colors.qualitative.Alphabet
        for i in range(min(100, n_sim)):
            fig_tray.add_trace(go.Scatter(
                x=forecast_dates,
                y=prices_sim[1:, i],
                mode='lines',
                line=dict(color=colors[i % len(colors)], width=1),
                opacity=0.2,
                hoverinfo='skip',
                showlegend=False
            ))

        # 2. Trayectorias destacadas
        fig_tray.add_trace(go.Scatter(
            x=forecast_dates,
            y=prices_sim[1:, 0],
            mode='lines',
            line=dict(color='#2ca02c', width=2),
            name="Trayectoria Inicial",
            hovertemplate="<b>Primera simulaci√≥n</b><br>%{y:$,.2f}<extra></extra>"
        ))

        fig_tray.add_trace(go.Scatter(
            x=forecast_dates,
            y=prices_sim[1:, -1],
            mode='lines',
            line=dict(color='#7f7f7f', width=2, dash='dot'),
            name="√öltima Trayectoria",
            hovertemplate="<b>√öltima simulaci√≥n</b><br>%{y:$,.2f}<extra></extra>"
        ))

        # 3. Media y bandas de percentiles
        lower_bound = np.percentile(prices_sim[1:], 5, axis=1)
        upper_bound = np.percentile(prices_sim[1:], 95, axis=1)

        fig_tray.add_trace(go.Scatter(
            x=forecast_dates,
            y=upper_bound,
            mode='lines',
            line=dict(width=0),
            showlegend=False,
            hoverinfo='skip'
        ))

        fig_tray.add_trace(go.Scatter(
            x=forecast_dates,
            y=lower_bound,
            mode='lines',
            line=dict(width=0),
            fill='tonexty',
            fillcolor='rgba(255, 165, 0, 0.2)',
            name="Banda de Confianza (90%)",
            hovertemplate="<b>Rango 5-95%</b><br>%{y:$,.2f}<extra></extra>"
        ))

        fig_tray.add_trace(go.Scatter(
            x=forecast_dates,
            y=price_mean[1:],
            mode='lines',
            line=dict(color='#ff7f0e', width=3),
            name="Media Simulaciones",
            hovertemplate="<b>Promedio</b><br>%{y:$,.2f}<extra></extra>"
        ))

        # 4. Anotaciones importantes
        fig_tray.add_annotation(
            x=full_dates[-1],
            y=price_mean[-1],
            text=f"Pron√≥stico Final<br>${price_mean[-1]:,.2f}",
            showarrow=True,
            arrowhead=4,
            ax=-50,
            ay=-40,
            font=dict(size=12, color="#2ca02c")
        )

        fig_tray.update_layout(
            title=f"‚úÖ Pron√≥stico Heston para {accion} - {n_sim} simulaciones",
            xaxis=dict(
                title="Fecha",
                rangeslider=dict(visible=True),
                type="date"
            ),
            yaxis_title="Precio (MXN)",
            hovermode="x unified",
            legend=dict(orientation="h", yanchor="bottom", y=1.02),
            template="plotly_white",
            margin=dict(l=20, r=20, t=60, b=20)
        )

        st.plotly_chart(fig_tray, use_container_width=True)

        # -----------------------------------------------------------------------------
        # Secci√≥n de An√°lisis de Riesgo
        # -----------------------------------------------------------------------------
        st.markdown("### üìä An√°lisis de Riesgo Cuantitativo")

        final_prices = prices_sim[-1, :]
        VaR_95 = np.percentile(final_prices, 5)
        CVaR_95 = final_prices[final_prices <= VaR_95].mean()
        max_loss = (VaR_95 - S0)/S0
        prob_ganancia = (final_prices > S0).mean()

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Value at Risk (95%)", f"${VaR_95:,.2f}",
                     help="P√©rdida m√°xima esperada en el peor 5% de casos")
        with col2:
            st.metric("Expected Shortfall", f"${CVaR_95:,.2f}",
                     help="P√©rdida promedio en el peor 5% de escenarios")
        with col3:
            st.metric("Probabilidad de Ganancia", f"{prob_ganancia:.1%}",
                     help="Probabilidad de que el precio final supere el actual")

        # Gr√°fico de distribuci√≥n de precios finales (CORREGIDO)
        fig_dist = ff.create_distplot(
            hist_data=[final_prices],
            group_labels=['Distribuci√≥n Precios'],
            show_hist=True,  # Cambiado a True para mejor visualizaci√≥n
            show_rug=False,
            bin_size=0.5*(final_prices.max() - final_prices.min())/100  # Autoajuste de bins
        )

        fig_dist.add_vline(
            x=S0,
            line_dash="dash",
            line_color="green",
            annotation_text="Precio Actual",
            annotation_position="top right"
        )

        fig_dist.update_layout(
            title="üì¶ Distribuci√≥n de Precios Finales Pronosticados",
            xaxis_title="Precio (MXN)",
            yaxis_title="Densidad",
            showlegend=False
        )
        st.plotly_chart(fig_dist, use_container_width=True)



        # -----------------------------------------------------------------------------
        # Simulador financiero para el modelo Heston
        # Se utiliza el promedio de las trayectorias (price_mean) como precio pronosticado
        # -----------------------------------------------------------------------------
        st.markdown("### üí∞ Simulador Financiero - Modelo Heston")
        monto = st.number_input("Monto a invertir (MXN)", min_value=0.0, value=10000.0, step=1000.0)
        precio_final = price_mean[-1]
        retorno = (precio_final / S0 - 1) * 100
        ganancia = monto * (precio_final / S0 - 1)
        monto_final = monto + ganancia
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Precio Actual", f"${S0:,.2f}")
        col2.metric("Precio Pronosticado", f"${precio_final:,.2f}", f"{retorno:.2f}%")
        col3.metric("Ganancia/P√©rdida", f"${ganancia:,.2f}")
        col4.metric("Monto Final", f"${monto_final:,.2f}")


#-------------------------------------------------------------------------------------------------------













    # =========================================================================
    # Secci√≥n 2: IA - Temporal Fusion Transformer
    # =========================================================================
    elif metodo_pronostico == "ü§ñ IA - Temporal Fusion Transformer":
        st.markdown("### ü§ñ IA - Temporal Fusion Transformer (TFT)")
        with st.expander("‚öôÔ∏è Par√°metros del Modelo", expanded=True):
            col1, col2 = st.columns(2)
            with col1:
                ventana = st.slider("Ventana Temporal (d√≠as)", 30, 365, 90,
                                    help="N√∫mero de d√≠as hist√≥ricos usados para cada predicci√≥n")
                epochs = st.slider("√âpocas de entrenamiento", 10, 500, 50,
                                   help="N√∫mero de iteraciones para entrenar el modelo (hiperpar√°metro)")
            with col2:
                batch_size = st.selectbox("Batch Size", [16, 32, 64, 128], index=1,
                                          help="Cantidad de muestras procesadas antes de actualizar los pesos del modelo (hiperpar√°metro)")
                learning_rate = st.selectbox("Learning Rate", [1e-4, 3e-4, 1e-3], index=1,
                                             help="Tasa de aprendizaje que determina el tama√±o de los pasos en la optimizaci√≥n (hiperpar√°metro)")
                st.markdown("#### Comentario:")
                st.markdown("ESTE MODELO ESTA PENDIENTE DE TERMINAR DE IMPLEMENTAR. Los hiperpar√°metros, como batch size y learning rate, influyen en c√≥mo aprende el modelo. Un batch size mayor puede ayudar a estabilizar el entrenamiento, mientras que un learning rate adecuado es clave para lograr una buena convergencia.")

        # Selecci√≥n de acci√≥n
        accion = st.selectbox("üìà Seleccione acci√≥n para pron√≥stico", options=selected_companies)

        # Cargar datos
        data = data_dict[accion]["Close"]
        returns = data.pct_change().dropna()

        # Preprocesamiento: divisi√≥n en datos de entrenamiento y prueba
        train_data = data.iloc[:-30]
        test_data = data.iloc[-30:]

        # Entrenamiento simulado (Placeholder: en producci√≥n se usar√≠a PyTorch/TensorFlow)
        @st.cache_resource
        def train_tft_model(_data, window_size, epochs, batch_size):
            # Este modelo simulado ilustra el proceso de entrenamiento.
            class FakeModel:
                def predict(self, data):
                    last_value = data.iloc[-1]
                    trend = np.linspace(last_value, last_value * 1.1, 30)
                    noise = np.random.normal(0, data.std() * 0.1, 30)
                    return trend + noise
            return FakeModel()

        model = train_tft_model(train_data, ventana, epochs, batch_size)
        pronostico = model.predict(train_data.iloc[-ventana:])

        # Generar fechas para el pron√≥stico
        last_date = data.index[-1]
        forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30, freq='B')

        # Visualizaci√≥n del pron√≥stico TFT
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=data.index, y=data, name="Hist√≥rico", line=dict(color='#1f77b4')))
        fig.add_trace(go.Scatter(x=forecast_dates, y=pronostico, name="Pron√≥stico TFT", line=dict(color='#2ca02c', dash='dot')))
        fig.update_layout(title=f"Pron√≥stico TFT para {accion}", xaxis_title="Fecha", yaxis_title="Precio (MXN)")
        st.plotly_chart(fig, use_container_width=True)

    # =========================================================================
    # Secci√≥n 3: Modelo Econom√©trico ARIMA-GARCH
    # =========================================================================
    else:
        st.markdown("### üìâ Modelo Econom√©trico ARIMA-GARCH (PENDIENTE DE TERMINAR DE IMPLEMENTAR)")

        # Selecci√≥n de acci√≥n
        accion = st.selectbox("üìà Seleccione acci√≥n para pron√≥stico", options=selected_companies)

        # Cargar datos
        data = data_dict[accion]["Close"]
        returns = data.pct_change().dropna()

        st.markdown("#### üßÆ An√°lisis Estad√≠stico Previo")
        # Prueba de Dickey-Fuller: eval√∫a la estacionariedad de la serie.
        adf_result = adfuller(data)
        adf_stat = adf_result[0]
        p_value = adf_result[1]
        st.write(f"**Estad√≠stico ADF:** {adf_stat:.4f}")
        st.write(f"**Valor p:** {p_value:.4f}")
        if p_value > 0.05:
            st.error("‚ö†Ô∏è La serie no es estacionaria. Se aplicar√° diferenciaci√≥n autom√°tica.")
            data_diff = data.diff().dropna()
            st.write("Se ha aplicado la diferenciaci√≥n a la serie para lograr estacionariedad.")
        else:
            st.success("‚úÖ La serie es estacionaria. No se requiere diferenciaci√≥n.")
            data_diff = data

        st.markdown("**Comentario:** La prueba ADF (Augmented Dickey-Fuller) determina si la serie tiene una ra√≠z unitaria. Un valor p mayor a 0.05 indica que la serie no es estacionaria.")

        # Graficar ACF y PACF en dos gr√°ficas peque√±as, una al lado de la otra
        fig_acf, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))
        from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
        plot_acf(data_diff, ax=ax1, lags=20)
        ax1.set_title("ACF")
        plot_pacf(data_diff, ax=ax2, lags=20, method='ywm')
        ax2.set_title("PACF")
        st.pyplot(fig_acf)

        # Selecci√≥n autom√°tica del modelo basado en AIC
        st.markdown("#### Selecci√≥n Autom√°tica del Modelo")
        best_aic = np.inf
        best_order = None
        for p in range(3):
            for d in range(2):
                for q in range(3):
                    try:
                        model_temp = ARIMA(data, order=(p, d, q))
                        results = model_temp.fit()
                        if results.aic < best_aic:
                            best_aic = results.aic
                            best_order = (p, d, q)
                    except:
                        continue
        st.write(f"Se ha seleccionado autom√°ticamente el modelo ARIMA{best_order} con el menor AIC: {best_aic:.2f}.")
        st.markdown("**Nota:** El modelo √≥ptimo se ha elegido autom√°ticamente en funci√≥n del AIC. Si lo deseas, puedes modificar manualmente los par√°metros.")

        # Par√°metros del modelo: opci√≥n manual
        with st.expander("‚öôÔ∏è Configuraci√≥n del Modelo (opcional)", expanded=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                p = st.number_input("Orden AR (p)", min_value=0, max_value=5, value=best_order[0])
            with col2:
                d = st.number_input("Orden de Diferenciaci√≥n (d)", min_value=0, max_value=2, value=best_order[1])
            with col3:
                q = st.number_input("Orden MA (q)", min_value=0, max_value=5, value=best_order[2])

        # Entrenamiento del modelo econom√©trico
        @st.cache_resource
        def train_econometric_model(_data, order):
            model = ARIMA(_data, order=order)
            return model.fit()

        model = train_econometric_model(data, (p, d, q))

        # Pron√≥stico
        forecast_steps = st.slider("D√≠as a pronosticar", 1, 365, 30)
        forecast = model.forecast(steps=forecast_steps)

        # Visualizaci√≥n del pron√≥stico
        fig_forecast_econ = go.Figure()
        fig_forecast_econ.add_trace(go.Scatter(x=data.index, y=data, name="Hist√≥rico", line=dict(color='#1f77b4')))
        forecast_index = pd.date_range(start=data.index[-1] + pd.Timedelta(days=1), periods=forecast_steps, freq='B')
        fig_forecast_econ.add_trace(go.Scatter(x=forecast_index, y=forecast, name="Pron√≥stico", line=dict(color='#9467bd', dash='dot')))
        fig_forecast_econ.update_layout(title=f"Pron√≥stico ARIMA-GARCH para {accion}", xaxis_title="Fecha", yaxis_title="Precio (MXN)")
        st.plotly_chart(fig_forecast_econ, use_container_width=True)

        st.markdown("#### üìä Resultados del Modelo")
        st.write(model.summary())




# ================================
# Pesta√±a 9: Distribuci√≥n Retornos
# ================================
with tab9:
    st.markdown("""
    ## üîç **An√°lisis Detallado del C√≥digo** üîç

    ### üßÆ 1. Correctitud Matem√°tica
    **üìä Portafolio NPEB (Pesta√±a 6):**
    - ‚úÖ **Acierto:** Implementaci√≥n correcta de Œº‚Çô y V‚Çô con bootstrap
    - ‚úÖ **Acierto:** Restricciones `sum(w)=1` y `w‚â•0` bien aplicadas
    - ‚ö†Ô∏è **Mejora:** Incorporar tasa libre de riesgo en c√°lculo de Sharpe ratio

    **üé≤ Modelo Heston (Pesta√±a 8):**
    - ‚úÖ **Acierto:** Ecuaciones diferenciales estoc√°sticas bien implementadas
    - ‚ö†Ô∏è **Advertencia:** `np.maximum` para volatilidad podr√≠a causar inestabilidad num√©rica

    **üìâ ARIMA-GARCH:**
    - ‚ùå **Error:** Falta componente GARCH completo
    - ‚úÖ **Acierto:** Prueba ADF y diferenciaci√≥n aplicadas correctamente

    ---

    ### üë®üíª 2. Buenas Pr√°cticas de Programaci√≥n
    - ‚úÖ **Excelente:** Uso eficiente de `@st.cache_data` para caching
    - ‚úÖ **Modular:** Funciones bien estructuradas y reutilizables
    - üîÑ **Oportunidad:** Eliminar duplicados en carga de datos
    - ‚úÖ **Robusto:** Manejo de errores con `try/except` en secciones cr√≠ticas


    """)

# ================================
# Pie de p√°gina
# ================================
st.markdown("---")
st.markdown("""
üéì **SEMINARIO DE INVERSI√ìN Y MERCADOS FINANCIEROS - IPN**
üßëüíª Realizado por **J. Cruz G√≥mez** ‚Ä¢ üìß josluigomez@gmail.com
üîÆ *"Los datos son como el acero: en bruto no valen, procesados son invencibles"*
""")


#GPT
